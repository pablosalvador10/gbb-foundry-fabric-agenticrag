{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94edb56d",
   "metadata": {},
   "source": [
    "# Query a Fabric Data Agent\n",
    "\n",
    "Call your **Fabric Data Agent** (Fabric IQ) programmatically. This is the same pattern used by `AirlineOpsContext` in the main app.\n",
    "\n",
    "```\n",
    "Your Question (natural language)\n",
    "        ‚Üì\n",
    "   Fabric Data Agent  \n",
    "        ‚Üì\n",
    "   Translates to SQL/DAX/KQL\n",
    "        ‚Üì\n",
    "   Queries OneLake warehouse\n",
    "        ‚Üì\n",
    "   Returns formatted answer\n",
    "```\n",
    "\n",
    "**Setup:** Replace `PUBLISHED_URL` with your agent's URL from **Fabric ‚Üí Agent Settings ‚Üí Published URL**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e942c",
   "metadata": {},
   "source": [
    "## 1) Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62dfc86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: synapseml==1.0.5 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (1.0.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: synapseml==1.0.5 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (1.0.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "agent-framework-core 1.0.0b251028 requires aiofiles>=24.1.0, which is not installed.\n",
      "agent-framework-core 1.0.0b251028 requires openai<2,>=1.99.0, but you have openai 1.70.0 which is incompatible.\n",
      "mem0ai 1.0.0 requires openai>=1.90.0, but you have openai 1.70.0 which is incompatible.\n",
      "semantic-kernel 1.28.1 requires pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.70.0\n",
      "  Using cached openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pablosal\\appdata\\roaming\\python\\python311\\site-packages (from openai==1.70.0) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pablosal\\appdata\\roaming\\python\\python311\\site-packages (from openai==1.70.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\pablosal\\appdata\\roaming\\python\\python311\\site-packages (from openai==1.70.0) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.70.0) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.70.0) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.70.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.70.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.70.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.70.0) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.70.0) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from tqdm>4->openai==1.70.0) (0.4.6)\n",
      "Using cached openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.109.1\n",
      "    Uninstalling openai-1.109.1:\n",
      "      Successfully uninstalled openai-1.109.1\n",
      "Successfully installed openai-1.70.0\n"
     ]
    }
   ],
   "source": [
    "%pip install \"openai==1.70.0\"\n",
    "%pip install \"synapseml==1.0.5\"\n",
    "%pip install pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91173718",
   "metadata": {},
   "source": [
    "## 2) Configure the Fabric client\n",
    "Uses OpenAI SDK with AAD auth to call your Fabric Data Agent endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2a09a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client configured. You're signed in with InteractiveBrowserCredential().\n"
     ]
    }
   ],
   "source": [
    "# pip install azure-identity openai==1.70.0\n",
    "\n",
    "# ---- REQUIRED: paste your Published URL here ----\n",
    "PUBLISHED_URL = \"https://msitapi.fabric.microsoft.com/v1/workspaces/00ae18cb-e789-4d42-be8d-a5b47e524e22/aiskills/1e363010-6005-48da-b370-7906177a760e/aiassistant/openai\"\n",
    "\n",
    "import typing as t\n",
    "import time, uuid\n",
    "\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from openai import OpenAI\n",
    "from openai._models import FinalRequestOptions\n",
    "from openai._types import Omit\n",
    "from openai._utils import is_given\n",
    "\n",
    "# ---------- Dev sign-in ----------\n",
    "# Opens a browser once; caches token locally\n",
    "SCOPE = \"https://api.fabric.microsoft.com/.default\"\n",
    "# If you see 401/403, swap to:\n",
    "# SCOPE = \"https://analysis.windows.net/powerbi/api/.default\"\n",
    "\n",
    "_cred = InteractiveBrowserCredential()\n",
    "\n",
    "def _get_bearer() -> str:\n",
    "    return _cred.get_token(SCOPE).token\n",
    "\n",
    "\n",
    "class FabricOpenAI(OpenAI):\n",
    "    \"\"\"\n",
    "    OpenAI client wrapper that:\n",
    "      - Uses your Fabric Data Agent Published URL as base_url\n",
    "      - Injects AAD Bearer token and correlation id\n",
    "      - Pins 'api-version' as query param\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, api_version: str = \"2024-05-01-preview\", **kwargs: t.Any\n",
    "    ) -> None:\n",
    "        self.api_version = api_version\n",
    "        default_query = kwargs.pop(\"default_query\", {})\n",
    "        default_query[\"api-version\"] = self.api_version\n",
    "        super().__init__(\n",
    "            api_key=\"\",  # not used\n",
    "            base_url=PUBLISHED_URL,  # IMPORTANT: your agent endpoint\n",
    "            default_query=default_query,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def _prepare_options(self, options: FinalRequestOptions) -> None:\n",
    "        headers: dict[str, str | Omit] = (\n",
    "            {**options.headers} if is_given(options.headers) else {}\n",
    "        )\n",
    "        headers[\"Authorization\"] = f\"Bearer {_get_bearer()}\"\n",
    "        headers.setdefault(\"Accept\", \"application/json\")\n",
    "        headers.setdefault(\"ActivityId\", str(uuid.uuid4()))\n",
    "        options.headers = headers\n",
    "        return super()._prepare_options(options)\n",
    "\n",
    "\n",
    "client = FabricOpenAI()\n",
    "print(\"Client configured. You're signed in with InteractiveBrowserCredential().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f194397",
   "metadata": {},
   "source": [
    "## 3) Helper function\n",
    "Ask natural language questions ‚Üí get data back from Fabric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4279e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper ready: call ask_data_agent('your question')\n",
      "   Deprecation warnings suppressed for cleaner output.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "def ask_data_agent(\n",
    "    question: str, poll_interval_sec: int = 2, timeout_sec: int = 300\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Sends a question to the published Fabric Data Agent and returns the text reply.\n",
    "    Cleans up the thread after completion.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create \"assistant\" placeholder (model is ignored by Fabric agent)\n",
    "        assistant = client.beta.assistants.create(model=\"not-used\")\n",
    "\n",
    "        # Create a new thread for this Q&A\n",
    "        thread = client.beta.threads.create()\n",
    "\n",
    "        try:\n",
    "            # Post the user message\n",
    "            client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=question,\n",
    "            )\n",
    "\n",
    "            # Start a run (the data agent actually does the work)\n",
    "            run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id, assistant_id=assistant.id\n",
    "            )\n",
    "\n",
    "            # Poll until terminal state or timeout\n",
    "            terminal = {\"completed\", \"failed\", \"cancelled\", \"requires_action\"}\n",
    "            start = time.time()\n",
    "            while run.status not in terminal:\n",
    "                if time.time() - start > timeout_sec:\n",
    "                    raise TimeoutError(\n",
    "                        f\"Run polling exceeded {timeout_sec}s (last status={run.status})\"\n",
    "                    )\n",
    "                time.sleep(poll_interval_sec)\n",
    "                run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            if run.status != \"completed\":\n",
    "                # Get detailed error information\n",
    "                error_msg = f\"‚ùå Run ended: {run.status}\"\n",
    "                if hasattr(run, 'last_error') and run.last_error:\n",
    "                    error_code = getattr(run.last_error, 'code', 'unknown')\n",
    "                    error_message = getattr(run.last_error, 'message', 'No details')\n",
    "                    error_msg += f\"\\n   Error Code: {error_code}\\n   Error Message: {error_message}\"\n",
    "                    \n",
    "                    # Add helpful context for common errors\n",
    "                    if \"MWC token\" in error_message or \"NL2Ontology\" in error_message:\n",
    "                        error_msg += \"\\n\\nüí° This is a Fabric Data Agent configuration issue.\"\n",
    "                        error_msg += \"\\n   The agent endpoint exists but has internal setup problems.\"\n",
    "                        error_msg += \"\\n   Please check:\"\n",
    "                        error_msg += \"\\n   - Agent is properly published in Fabric workspace\"\n",
    "                        error_msg += \"\\n   - Data sources are configured and accessible\"\n",
    "                        error_msg += \"\\n   - Workspace permissions are correct\"\n",
    "                    elif \"EntityNotFound\" in error_message or \"404\" in error_message:\n",
    "                        error_msg += \"\\n\\nüí° The Fabric Data Agent endpoint doesn't exist or was deleted.\"\n",
    "                        error_msg += \"\\n   Please verify the Published URL in your Fabric workspace.\"\n",
    "                        \n",
    "                return error_msg\n",
    "\n",
    "            # Collect messages in ascending order and concatenate text parts\n",
    "            msgs = client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "            out_chunks = []\n",
    "            for m in msgs.data:\n",
    "                if m.role == \"assistant\":\n",
    "                    for c in m.content:\n",
    "                        if getattr(c, \"type\", None) == \"text\":\n",
    "                            out_chunks.append(c.text.value)\n",
    "            return \"\\n\".join(out_chunks).strip() or \"[No text content returned]\"\n",
    "\n",
    "        finally:\n",
    "            # Always attempt cleanup\n",
    "            try:\n",
    "                client.beta.threads.delete(thread_id=thread.id)\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Exception during agent query: {type(e).__name__}: {str(e)}\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper ready: call ask_data_agent('your question')\")\n",
    "print(\"   Deprecation warnings suppressed for cleaner output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b5a4e",
   "metadata": {},
   "source": [
    "## 4) Try it out\n",
    "Ask questions about your data - Fabric IQ translates to SQL automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126173a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ask_data_agent(\"what are the most repeated routes for SkyBridge Airlines and NorthCoast Airlines in the last year?\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gbb-foundry-agenticrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
