{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94edb56d",
   "metadata": {},
   "source": [
    "# Query a Fabric Data Agent from a Notebook (Preview)\n",
    "\n",
    "This notebook shows how to call your **published Fabric Data Agent** programmatically using the OpenAI Assistants-style API.\n",
    "\n",
    "> **Replace `PUBLISHED_URL` below** with the value you see under your agent **Settings ‚Üí Published URL**.\n",
    "\n",
    "**What this notebook does**\n",
    "- Authenticates with your Fabric workspace using your notebook identity (AAD bearer).\n",
    "- Calls your **published Data Agent** via the OpenAI SDK.\n",
    "- Polls with a timeout (prevents infinite loops).\n",
    "- Cleans up created threads to conserve capacity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9e942c",
   "metadata": {},
   "source": [
    "## 1) Install dependencies (safe to re-run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62dfc86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: synapseml==1.0.5 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (1.0.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: synapseml==1.0.5 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (1.0.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2.3.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~penai (c:\\Users\\pablosal\\AppData\\Local\\anaconda3\\envs\\azure-ai-agent-service-demo\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "agent-framework-core 1.0.0b251028 requires aiofiles>=24.1.0, which is not installed.\n",
      "agent-framework-core 1.0.0b251028 requires openai<2,>=1.99.0, but you have openai 1.70.0 which is incompatible.\n",
      "mem0ai 1.0.0 requires openai>=1.90.0, but you have openai 1.70.0 which is incompatible.\n",
      "semantic-kernel 1.28.1 requires pydantic!=2.10.0,!=2.10.1,!=2.10.2,!=2.10.3,<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.70.0\n",
      "  Using cached openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pablosal\\appdata\\roaming\\python\\python311\\site-packages (from openai==1.70.0) (4.11.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pablosal\\appdata\\roaming\\python\\python311\\site-packages (from openai==1.70.0) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\pablosal\\appdata\\roaming\\python\\python311\\site-packages (from openai==1.70.0) (0.11.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (2.12.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from openai==1.70.0) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from anyio<5,>=3.5.0->openai==1.70.0) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.70.0) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from httpx<1,>=0.23.0->openai==1.70.0) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.70.0) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.70.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.70.0) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from pydantic<3,>=1.9.0->openai==1.70.0) (0.4.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\pablosal\\appdata\\local\\anaconda3\\envs\\azure-ai-agent-service-demo\\lib\\site-packages (from tqdm>4->openai==1.70.0) (0.4.6)\n",
      "Using cached openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.109.1\n",
      "    Uninstalling openai-1.109.1:\n",
      "      Successfully uninstalled openai-1.109.1\n",
      "Successfully installed openai-1.70.0\n"
     ]
    }
   ],
   "source": [
    "%pip install \"openai==1.70.0\"\n",
    "%pip install \"synapseml==1.0.5\"\n",
    "%pip install pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91173718",
   "metadata": {},
   "source": [
    "## 2) Configure the client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a2a09a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client configured. You're signed in with InteractiveBrowserCredential().\n"
     ]
    }
   ],
   "source": [
    "# pip install azure-identity openai==1.70.0\n",
    "\n",
    "# ---- REQUIRED: paste your Published URL here ----\n",
    "PUBLISHED_URL = \"https://msitapi.fabric.microsoft.com/v1/workspaces/00ae18cb-e789-4d42-be8d-a5b47e524e22/aiskills/1e363010-6005-48da-b370-7906177a760e/aiassistant/openai\"\n",
    "\n",
    "import typing as t\n",
    "import time, uuid\n",
    "\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from openai import OpenAI\n",
    "from openai._models import FinalRequestOptions\n",
    "from openai._types import Omit\n",
    "from openai._utils import is_given\n",
    "\n",
    "# ---------- Dev sign-in ----------\n",
    "# Opens a browser once; caches token locally\n",
    "SCOPE = \"https://api.fabric.microsoft.com/.default\"\n",
    "# If you see 401/403, swap to:\n",
    "# SCOPE = \"https://analysis.windows.net/powerbi/api/.default\"\n",
    "\n",
    "_cred = InteractiveBrowserCredential()\n",
    "\n",
    "\n",
    "def _get_bearer() -> str:\n",
    "    return _cred.get_token(SCOPE).token\n",
    "\n",
    "\n",
    "class FabricOpenAI(OpenAI):\n",
    "    \"\"\"\n",
    "    OpenAI client wrapper that:\n",
    "      - Uses your Fabric Data Agent Published URL as base_url\n",
    "      - Injects AAD Bearer token and correlation id\n",
    "      - Pins 'api-version' as query param\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, api_version: str = \"2024-05-01-preview\", **kwargs: t.Any\n",
    "    ) -> None:\n",
    "        self.api_version = api_version\n",
    "        default_query = kwargs.pop(\"default_query\", {})\n",
    "        default_query[\"api-version\"] = self.api_version\n",
    "        super().__init__(\n",
    "            api_key=\"\",  # not used\n",
    "            base_url=PUBLISHED_URL,  # IMPORTANT: your agent endpoint\n",
    "            default_query=default_query,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def _prepare_options(self, options: FinalRequestOptions) -> None:\n",
    "        headers: dict[str, str | Omit] = (\n",
    "            {**options.headers} if is_given(options.headers) else {}\n",
    "        )\n",
    "        headers[\"Authorization\"] = f\"Bearer {_get_bearer()}\"\n",
    "        headers.setdefault(\"Accept\", \"application/json\")\n",
    "        headers.setdefault(\"ActivityId\", str(uuid.uuid4()))\n",
    "        options.headers = headers\n",
    "        return super()._prepare_options(options)\n",
    "\n",
    "\n",
    "client = FabricOpenAI()\n",
    "print(\"Client configured. You're signed in with InteractiveBrowserCredential().\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f194397",
   "metadata": {},
   "source": [
    "## 3) Helper to ask the Data Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4279e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper ready: call ask_data_agent('your question')\n",
      "   Deprecation warnings suppressed for cleaner output.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "def ask_data_agent(\n",
    "    question: str, poll_interval_sec: int = 2, timeout_sec: int = 300\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Sends a question to the published Fabric Data Agent and returns the text reply.\n",
    "    Cleans up the thread after completion.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Create \"assistant\" placeholder (model is ignored by Fabric agent)\n",
    "        assistant = client.beta.assistants.create(model=\"not-used\")\n",
    "\n",
    "        # Create a new thread for this Q&A\n",
    "        thread = client.beta.threads.create()\n",
    "\n",
    "        try:\n",
    "            # Post the user message\n",
    "            client.beta.threads.messages.create(\n",
    "                thread_id=thread.id,\n",
    "                role=\"user\",\n",
    "                content=question,\n",
    "            )\n",
    "\n",
    "            # Start a run (the data agent actually does the work)\n",
    "            run = client.beta.threads.runs.create(\n",
    "                thread_id=thread.id, assistant_id=assistant.id\n",
    "            )\n",
    "\n",
    "            # Poll until terminal state or timeout\n",
    "            terminal = {\"completed\", \"failed\", \"cancelled\", \"requires_action\"}\n",
    "            start = time.time()\n",
    "            while run.status not in terminal:\n",
    "                if time.time() - start > timeout_sec:\n",
    "                    raise TimeoutError(\n",
    "                        f\"Run polling exceeded {timeout_sec}s (last status={run.status})\"\n",
    "                    )\n",
    "                time.sleep(poll_interval_sec)\n",
    "                run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "\n",
    "            if run.status != \"completed\":\n",
    "                # Get detailed error information\n",
    "                error_msg = f\"‚ùå Run ended: {run.status}\"\n",
    "                if hasattr(run, 'last_error') and run.last_error:\n",
    "                    error_code = getattr(run.last_error, 'code', 'unknown')\n",
    "                    error_message = getattr(run.last_error, 'message', 'No details')\n",
    "                    error_msg += f\"\\n   Error Code: {error_code}\\n   Error Message: {error_message}\"\n",
    "                    \n",
    "                    # Add helpful context for common errors\n",
    "                    if \"MWC token\" in error_message or \"NL2Ontology\" in error_message:\n",
    "                        error_msg += \"\\n\\nüí° This is a Fabric Data Agent configuration issue.\"\n",
    "                        error_msg += \"\\n   The agent endpoint exists but has internal setup problems.\"\n",
    "                        error_msg += \"\\n   Please check:\"\n",
    "                        error_msg += \"\\n   - Agent is properly published in Fabric workspace\"\n",
    "                        error_msg += \"\\n   - Data sources are configured and accessible\"\n",
    "                        error_msg += \"\\n   - Workspace permissions are correct\"\n",
    "                    elif \"EntityNotFound\" in error_message or \"404\" in error_message:\n",
    "                        error_msg += \"\\n\\nüí° The Fabric Data Agent endpoint doesn't exist or was deleted.\"\n",
    "                        error_msg += \"\\n   Please verify the Published URL in your Fabric workspace.\"\n",
    "                        \n",
    "                return error_msg\n",
    "\n",
    "            # Collect messages in ascending order and concatenate text parts\n",
    "            msgs = client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "            out_chunks = []\n",
    "            for m in msgs.data:\n",
    "                if m.role == \"assistant\":\n",
    "                    for c in m.content:\n",
    "                        if getattr(c, \"type\", None) == \"text\":\n",
    "                            out_chunks.append(c.text.value)\n",
    "            return \"\\n\".join(out_chunks).strip() or \"[No text content returned]\"\n",
    "\n",
    "        finally:\n",
    "            # Always attempt cleanup\n",
    "            try:\n",
    "                client.beta.threads.delete(thread_id=thread.id)\n",
    "            except Exception:\n",
    "                pass\n",
    "                \n",
    "    except Exception as e:\n",
    "        return f\"‚ùå Exception during agent query: {type(e).__name__}: {str(e)}\"\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper ready: call ask_data_agent('your question')\")\n",
    "print(\"   Deprecation warnings suppressed for cleaner output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8b5a4e",
   "metadata": {},
   "source": [
    "## 4) Quick sanity tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "594e82ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the results for the last year:\n",
      "\n",
      "1. SkyBridge Airlines ‚Äî Total Flights: 208, Total Kilometers: 507,971 km\n",
      "2. NorthCoast Air ‚Äî Total Flights: 192, Total Kilometers: 492,576 km\n",
      "\n",
      "The numbers are ordered by airline name, with total flights and total kilometers shown for each.\n"
     ]
    }
   ],
   "source": [
    "print(ask_data_agent(\"For NorthCoast Air and SkyBridge Airlines, provide the total number of flights and the total kilometers flown in the last year. Give the results in order, with airline names, total flights, and total kilometers.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "126173a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[No text content returned]\n"
     ]
    }
   ],
   "source": [
    "print(ask_data_agent(\"what are the most repeated routes for SkyBridge Airlines and NorthCoast Airlines in the last year?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56619144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have access to data from clinical glucose monitoring studies, specifically focused on comparing the accuracy and reliability of two glucose monitoring products: Product A and Product B. The data includes the following:\n",
      "\n",
      "- Glucose ranges (in mg/dL): Different glycemic levels for analysis (e.g., hypoglycemia, euglycemia, hyperglycemia).\n",
      "- MARD percentages: Mean Absolute Relative Difference, a key accuracy metric for glucose monitors.\n",
      "- Accuracy within ¬±20 mg/dL or ¬±20%: The percentage of sensor readings that are within ¬±20 mg/dL or ¬±20% of reference (lab) values.\n",
      "- Total readings: Number of glucose readings analyzed per product in each glucose range.\n",
      "\n",
      "The dataset comes from referenced clinical studies comparing CGM product performance and is structured to allow evaluation of product accuracy across all critical glucose ranges.\n",
      "\n",
      "If you have questions about product accuracy, performance in specific glucose ranges, comparative analysis, or clinically relevant implications, I can retrieve and analyze this data for you.\n",
      "Product A underperforms compared to Product B in all assessed glucose ranges, including:\n",
      "\n",
      "- Severe hypoglycemia (<54 mg/dL and 54‚Äì69 mg/dL)\n",
      "- General hypoglycemia (<70 mg/dL)\n",
      "- Euglycemia (70‚Äì180 mg/dL)\n",
      "- Mild to moderate hyperglycemia (181‚Äì250 mg/dL)\n",
      "- Severe hyperglycemia (>250 mg/dL)\n",
      "- All combined ranges (‚â•70 mg/dL, total dataset)\n",
      "\n",
      "In all these segments, Product A has higher (worse) MARD percentages and lower accuracy within ¬±20 mg/dL/¬±20% compared to Product B.\n",
      "\n",
      "Clinical impact of this underperformance:\n",
      "- In low glucose (<70 mg/dL): Lower accuracy and higher MARD may lead to missed or delayed detection of hypoglycemia, risking severe events or inadequate treatment adjustments.\n",
      "- In target and high ranges (>70 mg/dL): Less reliable readings could prompt suboptimal therapeutic decisions, either over-treating or under-treating, increasing the likelihood of both hypo- and hyperglycemic episodes.\n",
      "- General confidence: Persistent underperformance may reduce trust in the device, affecting patient adherence and overall glucose management.\n",
      "\n",
      "In summary, Product A‚Äôs lower accuracy in all glucose ranges can lead to greater clinical risk, less optimal diabetes management, and reduced safety for users.\n",
      "It appears that I do not have access to schema information or column lists for the tables \"factinternetsales\" and \"dimcustomer\" in the available dataset. The current data source is related to clinical glucose monitoring studies and does not include these specific tables.\n",
      "\n",
      "If you need columns from these tables for another database or system, please ensure the relevant data is accessible or clarify the context so I can assist further.\n",
      "It appears that information about Internet Sales by year and month is not available in the provided clinical glucose monitoring dataset. The data here focuses on glucose monitoring product accuracy, not sales metrics. If you would like information about glucose monitoring device comparisons, accuracy measures, or related analyses, please specify your question and I can assist!\n"
     ]
    }
   ],
   "source": [
    "# A. Connectivity / scope test\n",
    "print(ask_data_agent(\"What data sources do you have access to?\"))\n",
    "\n",
    "# B. Schema probe (adjust table names to your selections)\n",
    "print(ask_data_agent(\"List 10 columns from factinternetsales and 10 from dimcustomer.\"))\n",
    "\n",
    "# C. Business question\n",
    "print(ask_data_agent(\"Total Internet Sales by year and month; return a small table.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f5de294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product A underperforms compared to Product B in all glucose ranges evaluated. Specifically:\n",
      "\n",
      "- In each glucose range, Product A has a higher MARD percentage (meaning greater average error) and lower accuracy (fewer readings within ¬±20 mg/dL or ¬±20% of reference) than Product B.\n",
      "- This underperformance is especially pronounced in the hypoglycemic ranges:\n",
      "  - For glucose <54 mg/dL: Product A MARD is 16.3% (vs. 12.2% for Product B), and accuracy is 60.8% (vs. 78.1% for Product B).\n",
      "  - For glucose 54 to 69 mg/dL: Product A MARD is 13.5% (vs. 9.3% for Product B), and accuracy is 68.7% (vs. 85.4% for Product B).\n",
      "- Across the hyperglycemic range (>250 mg/dL), Product A also lags: MARD is 10.8% (vs. 7.0% for Product B); accuracy is 80.2% (vs. 94.5% for Product B).\n",
      "\n",
      "Clinical Impact:\n",
      "- Inaccurate detection of hypoglycemia (<70 mg/dL) increases the risk of unrecognized and untreated low glucose events, which can lead to severe medical emergencies (e.g., seizures, unconsciousness).\n",
      "- In hyperglycemic ranges, less accurate readings can delay recognition and treatment of high glucose, increasing risks for complications such as diabetic ketoacidosis.\n",
      "- Overall, Product A‚Äôs reduced accuracy across all ranges could negatively impact clinical decision-making and patient safety, especially in critical low and high glucose situations.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    ask_data_agent(\n",
    "        \"In which glucose ranges does Product A underperform compared to Product B, and what clinical impact could this have?\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c094af",
   "metadata": {},
   "source": [
    "## 5) Example analytics question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b6393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "Calculate the average percentage increase in sales amount for repeat purchases\n",
    "for every zipcode (repeat = any purchase after the first for that customer).\n",
    "Return the results in a compact table: zipcode, avg_pct_increase.\n",
    "\"\"\"\n",
    "print(ask_data_agent(q))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-agent-service-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
