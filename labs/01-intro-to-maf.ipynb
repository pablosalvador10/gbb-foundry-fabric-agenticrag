{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9cd3bd7b",
   "metadata": {},
   "source": [
    "# Intro to Microsoft Agent Framework (MAF)\n",
    "\n",
    "Learn the patterns used in the main app (`app/main.py`):\n",
    "1. **Foundry Agent** - Azure AI Agent Service (RealtimeAssistant)\n",
    "2. **Fabric Data Agent** - OneLake/SQL queries (AirlineOpsContext)\n",
    "3. **Orchestration** - Router + `.as_tool()` pattern\n",
    "\n",
    "**Prerequisites:** `az login`, env vars configured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d800f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q agent-framework azure-identity azure-ai-projects openai>=1.70.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc33db60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import asyncio\n",
    "from typing import Annotated\n",
    "from pydantic import Field\n",
    "\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework.azure import AzureAIAgentClient, AzureOpenAIChatClient\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "\n",
    "# Check env vars\n",
    "required = [\"AZURE_AI_PROJECT_ENDPOINT\", \"AZURE_OPENAI_API_ENDPOINT\", \"AZURE_OPENAI_KEY\"]\n",
    "missing = [k for k in required if not os.getenv(k)]\n",
    "print(\"âœ… Ready\" if not missing else f\"âš ï¸ Missing: {missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78fdd9e",
   "metadata": {},
   "source": [
    "## 1. Foundry Agent (RealtimeAssistant)\n",
    "Connect to Azure AI Agent Service - used for Bing search, weather, file search in `app/main.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b6ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def build_foundry_agent(agent_id: str) -> ChatAgent:\n",
    "    \"\"\"Connect to existing Azure AI Foundry agent.\"\"\"\n",
    "    endpoint = os.environ[\"AZURE_AI_PROJECT_ENDPOINT\"]\n",
    "    cred = AzureCliCredential()\n",
    "    project = AIProjectClient(endpoint=endpoint, credential=cred)\n",
    "    \n",
    "    chat_client = AzureAIAgentClient(project_client=project, agent_id=agent_id, credential=cred)\n",
    "    return ChatAgent(\n",
    "        chat_client=chat_client,\n",
    "        name=\"FoundryAgent\",\n",
    "        description=\"Azure AI Foundry agent\",\n",
    "    )\n",
    "\n",
    "# Replace with your agent ID\n",
    "AGENT_ID = \"asst_c5nsKgXECwvlBafUNpOFjuZO\"\n",
    "foundry_agent = await build_foundry_agent(AGENT_ID)\n",
    "\n",
    "result = await foundry_agent.run(\"What's the weather in Madrid?\")\n",
    "print(result.text if hasattr(result, 'text') else result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12406abc",
   "metadata": {},
   "source": [
    "## 2. Fabric Data Agent (AirlineOpsContext)\n",
    "Query OneLake data via Fabric IQ - used for airline operations queries in `app/main.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, uuid\n",
    "from azure.identity import InteractiveBrowserCredential\n",
    "from openai import OpenAI\n",
    "from openai._models import FinalRequestOptions\n",
    "\n",
    "FABRIC_ENDPOINT = \"https://msitapi.fabric.microsoft.com/v1/workspaces/00ae18cb-e789-4d42-be8d-a5b47e524e22/aiskills/1e363010-6005-48da-b370-7906177a760e/aiassistant/openai\"\n",
    "_cred = InteractiveBrowserCredential()\n",
    "\n",
    "class FabricOpenAI(OpenAI):\n",
    "    def __init__(self, base_url: str, **kwargs):\n",
    "        super().__init__(api_key=\"\", base_url=base_url, default_query={\"api-version\": \"2024-05-01-preview\"}, **kwargs)\n",
    "    \n",
    "    def _prepare_options(self, options: FinalRequestOptions) -> None:\n",
    "        options.headers = {**getattr(options, 'headers', {}),\n",
    "            \"Authorization\": f\"Bearer {_cred.get_token('https://api.fabric.microsoft.com/.default').token}\",\n",
    "            \"ActivityId\": str(uuid.uuid4())}\n",
    "        return super()._prepare_options(options)\n",
    "\n",
    "fabric_client = FabricOpenAI(base_url=FABRIC_ENDPOINT)\n",
    "\n",
    "def ask_fabric(question: str, timeout_sec: int = 300) -> str:\n",
    "    \"\"\"Query Fabric Data Agent.\"\"\"\n",
    "    assistant = fabric_client.beta.assistants.create(model=\"not-used\")\n",
    "    thread = fabric_client.beta.threads.create()\n",
    "    try:\n",
    "        fabric_client.beta.threads.messages.create(thread_id=thread.id, role=\"user\", content=question)\n",
    "        run = fabric_client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)\n",
    "        \n",
    "        start = time.time()\n",
    "        while run.status not in {\"completed\", \"failed\", \"cancelled\"}:\n",
    "            if time.time() - start > timeout_sec: raise TimeoutError(\"Timeout\")\n",
    "            time.sleep(2)\n",
    "            run = fabric_client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "        \n",
    "        if run.status != \"completed\": return f\"[Run ended: {run.status}]\"\n",
    "        msgs = fabric_client.beta.threads.messages.list(thread_id=thread.id, order=\"asc\")\n",
    "        return \"\\n\".join(c.text.value for m in msgs.data if m.role == \"assistant\" for c in m.content if c.type == \"text\")\n",
    "    finally:\n",
    "        try: fabric_client.beta.threads.delete(thread_id=thread.id)\n",
    "        except: pass\n",
    "\n",
    "print(ask_fabric(\"What data do you have access to?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a989d5ea",
   "metadata": {},
   "source": [
    "## 3. Wrap Fabric as a Tool\n",
    "Expose Fabric queries as a callable tool for an orchestrator agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239fca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fabric_query(question: Annotated[str, Field(description=\"Data query\")]) -> str:\n",
    "    \"\"\"Query operational data from Fabric.\"\"\"\n",
    "    return ask_fabric(question)\n",
    "\n",
    "unified_agent = ChatAgent(\n",
    "    chat_client=AzureOpenAIChatClient(\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        deployment_name=os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\"),\n",
    "    ),\n",
    "    name=\"UnifiedAgent\",\n",
    "    description=\"Agent with Fabric data access\",\n",
    "    instructions=\"Call fabric_query for data questions. Answer general questions directly.\",\n",
    "    tools=[fabric_query],\n",
    ")\n",
    "\n",
    "result = await unified_agent.run(\"What's the product A MARD comparison with Product B?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dda747",
   "metadata": {},
   "source": [
    "## 4. Router Pattern (Deterministic)\n",
    "Simple keyword-based routing - choose between Foundry (realtime) and Fabric (data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85b6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(query: str) -> str:\n",
    "    q = query.lower()\n",
    "    if any(w in q for w in [\"flights\", \"baggage\", \"airport\", \"routes\", \"sla\"]):\n",
    "        return \"fabric\"  # AirlineOpsContext\n",
    "    return \"foundry\"  # RealtimeAssistant (weather, time, web search)\n",
    "\n",
    "async def ask(query: str) -> str:\n",
    "    choice = route(query)\n",
    "    print(f\"ðŸŽ¯ â†’ {choice}\")\n",
    "    if choice == \"fabric\": \n",
    "        return (await unified_agent.run(query)).text\n",
    "    return (await foundry_agent.run(query)).text\n",
    "\n",
    "# Test\n",
    "print(await ask(\"What flights are delayed at ORD?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee805322",
   "metadata": {},
   "source": [
    "## 5. Router Pattern with .as_tool()\n",
    "This is how `app/main.py` works - LLM orchestrator decides which sub-agent to call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5c63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This mirrors the AirlineIntelligentAssistant orchestrator in app/main.py\n",
    "router_agent = ChatAgent(\n",
    "    chat_client=AzureOpenAIChatClient(\n",
    "        endpoint=os.getenv(\"AZURE_OPENAI_API_ENDPOINT\"),\n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        deployment_name=os.getenv(\"AZURE_AOAI_CHAT_MODEL_NAME_DEPLOYMENT_ID\"),\n",
    "    ),\n",
    "    name=\"Orchestrator\",\n",
    "    instructions=(\n",
    "        \"Route to the appropriate agent:\\n\"\n",
    "        \"â€¢ AirlineOpsContext â†’ flights, baggage, routes, airports, SLA metrics\\n\"\n",
    "        \"â€¢ RealtimeAssistant â†’ weather, time, web search, current events\"\n",
    "    ),\n",
    "    tools=[\n",
    "        unified_agent.as_tool(name=\"AirlineOpsContext\", description=\"Query Fabric for airline operations data\"),\n",
    "        foundry_agent.as_tool(name=\"RealtimeAssistant\", description=\"Weather, time, web search\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "result = await router_agent.run(\"What flights are delayed and what's the weather in Chicago?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb33fc5",
   "metadata": {},
   "source": [
    "## 6. Magentic Orchestration (Multi-round)\n",
    "Advanced orchestration with streaming - useful for complex multi-step tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051826af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import MagenticBuilder, MagenticFinalResultEvent, MagenticAgentDeltaEvent\n",
    "\n",
    "async def run_magentic(query: str):\n",
    "    workflow = MagenticBuilder().participants(router=router_agent).with_standard_manager(max_round_count=6).build()\n",
    "    \n",
    "    async for event in workflow.run_stream(query):\n",
    "        if isinstance(event, MagenticAgentDeltaEvent) and event.text:\n",
    "            print(event.text, end=\"\", flush=True)\n",
    "        elif isinstance(event, MagenticFinalResultEvent) and event.message:\n",
    "            print(f\"\\n\\n=== FINAL ===\\n{event.message.text}\")\n",
    "\n",
    "await run_magentic(\"Pull Q3 revenue KPIs and link me to the source file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7992a3a",
   "metadata": {},
   "source": [
    "## 7. Observability (Middleware)\n",
    "Add logging to see which tools get called - helpful for debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477d2ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework import FunctionInvocationContext, ChatContext\n",
    "\n",
    "async def log_tools(ctx: FunctionInvocationContext, nxt):\n",
    "    print(f\"[Tool] {ctx.function.name}({ctx.arguments})\")\n",
    "    await nxt(ctx)\n",
    "\n",
    "async def log_llm(ctx: ChatContext, nxt):\n",
    "    print(f\"[LLM] {len(ctx.messages)} messages\")\n",
    "    await nxt(ctx)\n",
    "\n",
    "router_agent.function_middlewares = [log_tools]\n",
    "router_agent.chat_middlewares = [log_llm]\n",
    "print(\"âœ… Middleware attached\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure-ai-agent-service-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
